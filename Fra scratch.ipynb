{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag stivariabler\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/suitsglasses'\n",
    "\n",
    "\n",
    "%pwd\n",
    "path = \"data/suitsglasses/\"\n",
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FCBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean of each channel as provided by VGG researchers\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939]).reshape((3,1,1))\n",
    "\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean     # subtract mean\n",
    "    return x[:, ::-1]    # reverse axis bgr->rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_16():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224)))\n",
    "\n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES_PATH = 'http://files.fast.ai/models/';\n",
    "fpath = get_file('vgg16.h5', FILES_PATH+'vgg16.h5', cache_subdir='models')\n",
    "model.load_weights(fpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=True, \n",
    "                batch_size=batch_size, class_mode='categorical'):\n",
    "    return gen.flow_from_directory(path+dirname, target_size=(224,224), \n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ft(model, num):\n",
    "    \"\"\"\n",
    "        Replace the last layer of the model with a Dense (fully connected) layer of num neurons.\n",
    "        Will also lock the weights of all layers except the new layer so that we only learn\n",
    "        weights for the last layer in subsequent training.\n",
    "\n",
    "        Args:\n",
    "            num (int) : Number of neurons in the Dense layer\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    model.pop()\n",
    "    for layer in model.layers: layer.trainable=False\n",
    "    model.add(Dense(num, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=0.0001),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune(model, batches):\n",
    "    \"\"\"\n",
    "        Modifies the original VGG16 network architecture and updates self.classes for new training data.\n",
    "\n",
    "        Args:\n",
    "            batches : A keras.preprocessing.image.ImageDataGenerator object.\n",
    "                      See definition for get_batches().\n",
    "    \"\"\"\n",
    "    ft(model,batches.nb_class)\n",
    "    classes = list(iter(batches.class_indices)) # get a list of all the class labels\n",
    "\n",
    "    # batches.class_indices is a dict with the class name as key and an index as value\n",
    "    # eg. {'cats': 0, 'dogs': 1}\n",
    "\n",
    "    # sort the class labels by index according to batches.class_indices and update model.classes\n",
    "    for c in batches.class_indices:\n",
    "        classes[batches.class_indices[c]] = c\n",
    "    model.classes = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(model, batches, val_batches, nb_epoch=1):\n",
    "    \"\"\"\n",
    "        Fits the model on data yielded batch-by-batch by a Python generator.\n",
    "        See Keras documentation: https://keras.io/models/model/\n",
    "    \"\"\"\n",
    "    model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n",
    "            validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches('train', batch_size=6)\n",
    "imgs,labels = next(batches)\n",
    "\n",
    "# This shows the 'ground truth'\n",
    "plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = get_batches('train', batch_size=batch_size)\n",
    "val_batches = get_batches('valid', batch_size=batch_size)\n",
    "finetune(model,batches)\n",
    "fit(model, batches, val_batches, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def predict(model, imgs, details=False):\n",
    "        \"\"\"\n",
    "            Predict the labels of a set of images using the VGG16 model.\n",
    "\n",
    "            Args:\n",
    "                imgs (ndarray)    : An array of N images (size: N x width x height x channels).\n",
    "                details : ??\n",
    "            \n",
    "            Returns:\n",
    "                preds (np.array) : Highest confidence value of the predictions for each image.\n",
    "                idxs (np.ndarray): Class index of the predictions with the max confidence.\n",
    "                classes (list)   : Class labels of the predictions with the max confidence.\n",
    "        \"\"\"\n",
    "        # predict probability of each class for each image\n",
    "        all_preds = model.predict(imgs)\n",
    "        # for each image get the index of the class with max probability\n",
    "        idxs = np.argmax(all_preds, axis=1)\n",
    "        # get the values of the highest probability for each image\n",
    "        preds = [all_preds[i, idxs[i]] for i in range(len(idxs))]\n",
    "        # get the label of the class with the highest probability for each image\n",
    "        classes = [model.classes[idx] for idx in idxs]\n",
    "        return np.array(preds), idxs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediker på våre testdata\n",
    "batches = get_batches('test', batch_size=6)\n",
    "imgs,labels = next(batches)\n",
    "\n",
    "plots(imgs, titles=labels)\n",
    "\n",
    "predict(model, imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
