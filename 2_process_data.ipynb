{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from numpy.random import random, permutation\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import util; reload(util)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lag stivariabler\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data/suitsglasses'\n",
    "\n",
    "\n",
    "%pwd\n",
    "path = \"data/suitsglasses/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvBlock(layers, model, filters):\n",
    "    for i in range(layers): \n",
    "        model.add(ZeroPadding2D((1,1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FCBlock(model):\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VGG_16():\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(vgg_preprocess, input_shape=(3,224,224)))\n",
    "\n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load precalculated weights\n",
    "fpath = LESSON_HOME_DIR + '/models/vgg16.h5'\n",
    "model.load_weights(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finetune(model, num):\n",
    "    \"\"\"\n",
    "        Replace the last layer of the model with a Dense (fully connected) layer of num neurons.\n",
    "        Will also lock the weights of all layers except the new layer so that we only learn\n",
    "        weights for the last layer in subsequent training.\n",
    "\n",
    "        Args:\n",
    "            num (int) : Number of neurons in the Dense layer\n",
    "        Returns:\n",
    "            None\n",
    "    \"\"\"\n",
    "    model.pop()\n",
    "    for layer in model.layers: layer.trainable=False\n",
    "    model.add(Dense(num, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(lr=0.0001),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.classes = ['glasses', 'suits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(model, batches, val_batches, nb_epoch=1):\n",
    "    \"\"\"\n",
    "        Fits the model on data yielded batch-by-batch by a Python generator.\n",
    "        See Keras documentation: https://keras.io/models/model/\n",
    "    \"\"\"\n",
    "    model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=nb_epoch,\n",
    "            validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = util.get_batches(path+'train', batch_size=4)\n",
    "\n",
    "imgs,labels = next(batches)\n",
    "# This shows the 'ground truth'\n",
    "util.plots(imgs, titles=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = util.get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = util.get_batches(path+'valid', batch_size=batch_size)\n",
    "finetune(model,2)\n",
    "fit(model, batches, val_batches, nb_epoch=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model weights\n",
    "fpath = LESSON_HOME_DIR + '/models/vgg16_sg.h5'\n",
    "print(fpath)\n",
    "model.save_weights(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, imgs, details=False):\n",
    "    \"\"\"\n",
    "        Predict the labels of a set of images using the VGG16 model.\n",
    "\n",
    "        Args:\n",
    "            imgs (ndarray)    : An array of N images (size: N x width x height x channels).\n",
    "            details : ??\n",
    "\n",
    "        Returns:\n",
    "            preds (np.array) : Highest confidence value of the predictions for each image.\n",
    "            idxs (np.ndarray): Class index of the predictions with the max confidence.\n",
    "            classes (list)   : Class labels of the predictions with the max confidence.\n",
    "    \"\"\"\n",
    "    # predict probability of each class for each image\n",
    "    all_preds = model.predict(imgs)\n",
    "    # for each image get the index of the class with max probability\n",
    "    idxs = np.argmax(all_preds, axis=1)\n",
    "    # get the values of the highest probability for each image\n",
    "    preds = [all_preds[i, idxs[i]] for i in range(len(idxs))]\n",
    "    # get the label of the class with the highest probability for each image\n",
    "    classes = [model.classes[idx] for idx in idxs]\n",
    "    return np.array(preds), idxs, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediker på våre testdata\n",
    "batches = util.get_batches(path+'test', batch_size=4)\n",
    "imgs,labels = next(batches)\n",
    "\n",
    "util.plots(imgs, titles=labels)\n",
    "\n",
    "predict(model, imgs, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
